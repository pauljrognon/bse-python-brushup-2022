{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414bfc8a",
   "metadata": {},
   "source": [
    "**Introductory and intermediate computing for Data Science [Barcelona School of Economics]**\n",
    "\n",
    "`Instructor:` Maxim Fedotov  \n",
    "`Program:` M.Sc. in Data Science Methodology\n",
    "\n",
    "# Class 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ff5c1",
   "metadata": {},
   "source": [
    "## Numpy package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24bc1f",
   "metadata": {},
   "source": [
    "The \"numpy\" package provides effective data structures and utilities to handle mathematical computations that involve collections of object.\n",
    "\n",
    "Let's first import the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa590ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # the name on the right is just a short name that I define for the notebook\n",
    "np.random.seed(1337)  # you will see later, why it is here (setting random state for the whole document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71da4108",
   "metadata": {},
   "source": [
    "Note that in the text I use a full name of the package. In fact, for serious applications it is not quite recommended to use short names. One of the reasons for that you can get when you check a type of any numpy class. Even though you provided a specific short name for the package in the current script, names of objects from there will still contain a full name of the package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4cfced",
   "metadata": {},
   "source": [
    "### Numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d0b6b4",
   "metadata": {},
   "source": [
    "A basic building block for the computations that we obtain from the package is `numpy.ndarray` (simply called a numpy array). You can create a numpy array using `numpy.array(...)` function. One more helpful function would be `numpy.arange(...)` which gives an array of incremented values (feel free to check out it's arguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1537e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = np.array([1, 2, 3])\n",
    "add = np.arange(3, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b203d1",
   "metadata": {},
   "source": [
    "The main advantage of `numpy` is that it provides all the tools for operations vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19eb6666",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  8, 13])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**powers + add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f69fd91",
   "metadata": {},
   "source": [
    "The core of the package is written in C++. It means that a well optimized code with propoer use of vectorized operations can give substantial computation time gains. You should always try utilize this feature as much as possible.\n",
    "\n",
    "Just a small example for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605ffd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a simple implementation through a list comprehension:\n",
      "--- time: 0.000286 ---\n",
      "For a numpy implementation:\n",
      "--- time: 0.000025 ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def inner_product_list_implementation(a: np.ndarray, b: np.ndarray):  # list comprehension implementation of\n",
    "    if a.size != b.size:                                              # inner product operation;\n",
    "        raise ValueError(f\"The two iterables must have the s\")        # note that I will still use numpy arrays\n",
    "    if a.ndim != 1 or b.ndim != 1:                                    # as arguments, but this won't help â€“\n",
    "        raise NotImplemented()                                        # we still need a proper vectorization\n",
    "    return [a * b for a, b in zip(a, b)]\n",
    "\n",
    "def measure_time(func, *args, **kwargs):  # utility to measure computation time\n",
    "    start = time.time()\n",
    "    func(*args, **kwargs)\n",
    "    end = time.time()\n",
    "    print(\"--- time: %f ---\" % (end - start))\n",
    "    \n",
    "    \n",
    "a = np.random.normal(0, 1, 1000)\n",
    "b = np.random.normal(0, 1, 1000)\n",
    "print(\"For a simple implementation through a list comprehension:\")\n",
    "measure_time(inner_product_list_implementation, a, b)\n",
    "print(\"For a numpy implementation:\")\n",
    "measure_time(np.inner, a, b)\n",
    "# the time difference depends on the size of collections involved in computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a729d",
   "metadata": {},
   "source": [
    "There are also many other ways to create specific arrays. The examples are presented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5713c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The array consists of 4 zeros: [0. 0. 0. 0.]\n",
      "The array consists of 4 ones: [1. 1. 1. 1.]\n",
      "The identity matrix of size 3 x 3:\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "zeros_array = np.zeros(4)\n",
    "print(\"The array consists of 4 zeros:\", zeros_array)\n",
    "\n",
    "ones_array = np.ones(4)  # \n",
    "print(\"The array consists of 4 ones:\", ones_array)\n",
    "\n",
    "identity_matrix = np.eye(3)  # note that, despite the name, it is a numpy array in Python\n",
    "print(\"The identity matrix of size 3 x 3:\", identity_matrix, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ec032a",
   "metadata": {},
   "source": [
    "Note that when you use \"print\" function the output looks like a list, but if you just call a numpy array in a notebook, you will instantly find out the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982c0ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62e622",
   "metadata": {},
   "source": [
    "As you can see from the identity matrix example above, numpy arrays can be multidimentional. Try to create a 2-dimensional array of zeros using the `numpy.zero(...)` function (note that you should use `np` instead of `numpy` in this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5bcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2478ce8b",
   "metadata": {},
   "source": [
    "You can also create a multidimensional array manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5f612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A number of dimensions of the array is: 3\n",
      "A number of dimensions of the array is: 8\n",
      "Shape of the array is: (2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "three_dimensional_array = np.array([[[1, 2], \n",
    "                                     [3, 4]], \n",
    "                                    [[5, 6], \n",
    "                                     [7, 8]]])\n",
    "\n",
    "# ndim is a useful propery of the numpy array\n",
    "print('A number of dimensions of the array is:', three_dimensional_array.ndim)\n",
    "\n",
    "# size too\n",
    "print('A number of dimensions of the array is:', three_dimensional_array.size)\n",
    "\n",
    "# you can also access shape of an array, it will correspond (sort of) to a mathematical \"size of a matrix\"\n",
    "print('Shape of the array is:', three_dimensional_array.shape) # shape property returns a tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430bc40",
   "metadata": {},
   "source": [
    "There are also some useful methods to transform the arrays. These are just some examples of them, which are the most popular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5b4a3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can reshape the array like this:\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n",
      "You can also transpose an array:\n",
      "[[1 5]\n",
      " [2 6]\n",
      " [3 7]\n",
      " [4 8]]\n",
      "The flattened version of the array is: [1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# you could also specify more dimensions or use an exact value insted of -1; \n",
    "# reshape figures out the size of a dimension itself if you put -1.\n",
    "print(\"We can reshape the array like this:\", reshaped_array := three_dimensional_array.reshape(-1, 4), sep=\"\\n\")  \n",
    "    \n",
    "print(\"You can also transpose an array:\", reshaped_array.transpose(), sep=\"\\n\")\n",
    "\n",
    "print(\"The flattened version of the array is:\", three_dimensional_array.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adae1cb",
   "metadata": {},
   "source": [
    "Try to transpose a flat array. What do you get and why? How do you think you can fix that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a192e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a0e9e",
   "metadata": {},
   "source": [
    "You can subset elements from the array by specifying proper *indices* or *slices* inside square brackets right after the corresponding identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7a9f0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use indices to select elements:\n",
      "0\n",
      "Use slices to select elements:\n",
      "[[ 1  2]\n",
      " [ 6  7]\n",
      " [11 12]]\n",
      "Use slices to select elements:\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "slice_it = np.arange(25).reshape(5, 5)\n",
    "\n",
    "print(\"Use indices to select elements:\", slice_it[0, 0], sep=\"\\n\")\n",
    "print(\"Use slices to select elements:\", slice_it[:3, 1:3], sep=\"\\n\")\n",
    "print(\"Use slices to select elements:\", slice_it[:3, :], sep=\"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31829d25",
   "metadata": {},
   "source": [
    "Any proper slice will do: `start:end` (where start and end are in fact optional). In addition, iterable objects that contain proper indices also will do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8dcb671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [ 6  7]\n",
      " [11 12]\n",
      " [16 17]\n",
      " [21 22]]\n",
      "[16 22]\n",
      "You cannot specify two iterables of different sizes!\n",
      "Error text: 'shape mismatch: indexing arrays could not be broadcast together with shapes (3,) (2,) '\n"
     ]
    }
   ],
   "source": [
    "print(slice_it[:, [1, 2]])\n",
    "print(slice_it[(3, 4), [1, 2]])  # note that if you use several iterables as indices, \n",
    "                                 # Python will try to broadcast them, i.e. this gives you elements \n",
    "                                 # at indices (3, 1) and (4, 2)\n",
    "try:\n",
    "    slice_it[(1, 3, 4), [1, 2]] \n",
    "except IndexError as error_text:\n",
    "    print(\"You cannot specify two iterables of different sizes!\", f\"Error text: '{error_text}'\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f320f",
   "metadata": {},
   "source": [
    "You can see that numpy arrays differ from the basic sequence types in this aspect too. For example, you are unable to select elements of a list with iterable objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ac2df8",
   "metadata": {},
   "source": [
    "Note that even though the `slice_it` array is two dimensional, we can specify one-dimensional index to subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89b0c34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_it[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af48d31",
   "metadata": {},
   "source": [
    "### Producing realizations of (pseudo-)random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fadc08a",
   "metadata": {},
   "source": [
    "The module that is responsible for random variable simulations is called `numpy.random`. You can find some of the available distributions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c06a1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 10 realizations of U[2, 5]:\n",
      " [2.98181964 4.7262762  4.31786114 3.15410594 2.36080876 2.94094805\n",
      " 2.61743937 3.35732478 2.05391737 2.09398573]\n",
      "This is 10 realizations of a r.v. uniformly distributed on integer values in [2, 5):\n",
      " [2 2 3 2 4 4 3 4 2 4]\n",
      "This is 10 realizations of a gaussian r.v. with mean 2 and st.dev. 4:\n",
      " [ 6.45121614  0.39676198  1.95631332  3.43166157  7.35690004  2.06571451\n",
      " -1.98160019 -0.90015354  7.42159615  0.53410108]\n"
     ]
    }
   ],
   "source": [
    "n_obs = 10\n",
    "\n",
    "print(f\"This is {n_obs} realizations of U[2, 5]:\\n\", np.random.uniform(low=2, high=5, size=n_obs))\n",
    "print(f\"This is {n_obs} realizations of a r.v. uniformly distributed on integer values in [2, 5):\\n\", \n",
    "      np.random.randint(low=2, high=5, size=n_obs))\n",
    "print(f\"This is {n_obs} realizations of a gaussian r.v. with mean 2 and st.dev. 4:\\n\", \n",
    "      np.random.normal(loc=2, scale=4, size=n_obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9d207",
   "metadata": {},
   "source": [
    "Note that these realizations are not purely random. In fact, nothing in your computer is not purely random. All these procedures are mostly called \"pseudo-random\" because they always depend on something, e.g. state of your hardware, software and other things.\n",
    "\n",
    "So, to make your code reproducible, it is a good tone to specify a concrete value of a \"seed\" like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6080334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da78a4",
   "metadata": {},
   "source": [
    "People who will run your script will then be able to check reliability of your results, they will get the same results in the parts of your code that exhibit randomness (through numpy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f66ef",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd47f10",
   "metadata": {},
   "source": [
    "JSON is a quite convenient data format when you work with data. You will meet it quite often if you will do web-scraping. However, it is not a restriction, its use is broad. There is a specific syntax for this data format. A simple example is presented below:\n",
    "\n",
    "```{JSON}\n",
    "{\"holder\": \"Foo\", \n",
    " \"account_no\": 1337, \n",
    " \"balance\": 100500}\n",
    "```\n",
    "\n",
    "However, it is not the only possible structure. It can be also: a dictionary where values are lists, a nested dictionary, a list of dictionaries and similar structures. Note that in JSON format you must not use single quotes `'`. \n",
    "\n",
    "In particular, these formats can be easily converted to pythonic objects. Package `json` gives us this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1583e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313ceb1",
   "metadata": {},
   "source": [
    "Let's have a look at how we can convert a simple string written in a JSON format into a pythonic object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "affbd8b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variable1': [4.45654794846065, 4.278310755227896, 3.009643269934777],\n",
       " 'variable2': [3, 3, 3]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_str = '{\"variable1\": [4.45654794846065, 4.278310755227896, 3.009643269934777], \"variable2\": [3, 3, 3]}'\n",
    "data = json.loads(json_str)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e223fc46",
   "metadata": {},
   "source": [
    "The `json.loads(...)` function \"loads\" a string, i.e. transforms it to a dictionary in this case. \n",
    "\n",
    "We also can write pythonic objects to test files with the \"json\" extension. We can use a *context manager* which allows us to open files and work with them in different modes. To define a context manager, we use keyword `with` together with `open(...)` function. In the `open(...)` function we specify a path to a file, and a mode in which we want to opent is, e.g. \"w\" for writing (but truncating an existing file at first), \"a\" to append content, \"r\" to read and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "619a005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"w\") as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf75eb3",
   "metadata": {},
   "source": [
    "You could do it in another way using just the `open(...)` function. But you **have to** close a file after use, otherwise you can encounter some problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "383179e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data.json\", \"w\")\n",
    "json.dump(data, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0146de",
   "metadata": {},
   "source": [
    "So, use of a *context manager* is preferrable.\n",
    "\n",
    "You can also read files with json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89ad35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"r\") as file:\n",
    "    data_new = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ec3df69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variable1': [4.45654794846065, 4.278310755227896, 3.009643269934777],\n",
       " 'variable2': [3, 3, 3]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d6c7a",
   "metadata": {},
   "source": [
    "Just as a comment, you can also read any text file line by line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c35a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"r\") as file:  # our file consists of only one line, but you get the idea\n",
    "    data_txt = []\n",
    "    for line in file:\n",
    "        data_txt.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03417fcc",
   "metadata": {},
   "source": [
    "You could also use functions like `file.readline(...)`, `file.readlines(...)`, `file.seek(...)` and others to work with files. Feel free to find out what they do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3beb8b",
   "metadata": {},
   "source": [
    "## Example: data simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f20e73",
   "metadata": {},
   "source": [
    "Let's consider an application of `numpy`. In theoretical studies, you might want to simulate some data to test your algorithm and obtain some quantitative performance metrics for it under some theoretical assumptions.\n",
    "\n",
    "In general, lets suppose that we want to generate and output according to the following linear model:\n",
    "$$y = X \\cdot \\beta + \\varepsilon$$\n",
    "where $y \\in \\mathbb{R}^{n}$ is an output variable, $X \\in \\mathbb{R}^{n \\times p}$ is a design matrix which consists of different covariates(variables) for each observation (written by columns), $\\beta \\in \\mathbb{R}^{p}$ is a vector of coefficients, $\\varepsilon \\sim \\mathcal{N}(0_n, I_n)$ is a noise.\n",
    "\n",
    "But first, we need to assume something about distribution of $X$. For our exercise, let's create a utility to simulate a design matrics and make it as abstract as we can. The following function is going to accept dictionaries that specify feature distributions and parameters for these distributions, as well as encodings for some features (we will get to that later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6a8d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import FunctionType\n",
    "\n",
    "def simulate_X(n: int, vars_dists: dict[FunctionType], dists_params: dict[dict], \n",
    "               encodings: dict[FunctionType]):\n",
    "    p = len(vars_dists)\n",
    "    # just for educational purposes, lets have our simulations in two formats: a dictionary and a numpy array\n",
    "    # you can easily save the dictionary to a .json file if you wish\n",
    "    X_dict = {}\n",
    "    X_array = np.ndarray((n, 0))\n",
    "    \n",
    "    for varname in vars_dists:\n",
    "        var_simulation = var_dists[varname](**dists_params[varname], size=n)\n",
    "        X_dict[varname] = var_simulation\n",
    "        if varname in encodings:\n",
    "            encoded_result, _ = encodings[varname](X_dict[varname])\n",
    "            X_array = np.hstack((X_array, encoded_result))\n",
    "        else:\n",
    "            X_array = np.hstack((X_array, var_simulation.reshape(n, -1)))\n",
    "    return X_dict, X_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf5ab0",
   "metadata": {},
   "source": [
    "Sometimes we deal with variables that take three or more values from a discrete set. For example, these could be different cities / countries, occupations, car models and so on. To work with them, we usually need to transform (encode) them to some numerical features. One possible way of doing that is to use One Hot Encoding. Namely, if we have $v$ possible values that a variable can take, to $v$ indicators that take values 0 or 1. (note that to use them later in a statistical model plainly you will have to drop one of them to get rid of *multicollinearity*).\n",
    "\n",
    "Let's implement a function which allows us to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "259e37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(array: np.ndarray):\n",
    "    unique_elements = np.unique(array)\n",
    "    encoded_result = np.zeros((array.size,  unique_elements.size))\n",
    "    for i in range(array.size):\n",
    "        encoded_result[i, :] = array[i] == unique_elements\n",
    "    return encoded_result, unique_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589a2c3",
   "metadata": {},
   "source": [
    "Now we can create our dataset. We will specify the following variables:\n",
    "* age â€“ integer number, age of a person\n",
    "* female â€“ binary, an indicator of sex\n",
    "* occupation â€“ one of the pre-specified values from the `occupations` list taken with equal probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "202dc872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41.,  1.,  0.,  1.,  0.,  0.],\n",
       "       [46.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [58.,  1.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupations = [\"data analyst\", \"data engineer\", \"software engineer\", \"tester\"]\n",
    "\n",
    "var_dists = {\"age\": np.random.randint, \"female\": np.random.binomial, \"occupation\": np.random.choice}\n",
    "dists_params = {\"age\": {\"low\": 18, \"high\": 65}, \"female\": {\"n\": 1, \"p\": 0.5}, \"occupation\": {\"a\": occupations}}\n",
    "\n",
    "X_dict, X = simulate_X(100, vars_dists=var_dists, dists_params=dists_params, \n",
    "                       encodings={\"occupation\": one_hot_encoding})\n",
    "\n",
    "X[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d32acae",
   "metadata": {},
   "source": [
    "Now we can finally move to creating our output variable according to the linear model:\n",
    "$$y = X \\cdot \\beta + \\varepsilon$$\n",
    "\n",
    "Luckily, we can use the matrix algebra operations that `numpy` provides us with. Here we use, for example, a `.dot(...)` method of a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef02903d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.66133414, 24.27141737, 30.10000886, 28.63220201, 20.53774962,\n",
       "       28.88624474, 21.61354079, 18.85999115, 20.44635657, 14.5289177 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = np.append(np.array([0.5, 0]), np.arange(0, 1, 0.25))\n",
    "y = X.dot(beta) + np.random.normal(0, 1, size=X.shape[0])\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ab50f",
   "metadata": {},
   "source": [
    "We could also multiply 2-d arrays or a 2-d array and a 1-d array using `@` operator, but it is a rather recent functionality. And it is not recommended for multiplying two one-dimensional arrays, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af7af2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75, 23.25, 29.75, 29.  , 21.75, 29.25, 22.  , 18.75, 19.5 ,\n",
       "       13.  ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X @ beta)[:10]  # it is different from the above because there is no noise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5e7b44",
   "metadata": {},
   "source": [
    "## Other linear algebra tools: numpy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb38575",
   "metadata": {},
   "source": [
    "Also, feel free to check out `linalg` module of numpy that has more linear algebra related functons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d49039ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have the following matrix:\n",
      " [[1. 1. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 1. 3.]]\n",
      "Determinant: 2.0\n",
      "Inverse:\n",
      " [[ 2.5 -1.  -0.5]\n",
      " [-1.   1.   0. ]\n",
      " [-0.5  0.   0.5]]\n",
      "Eigenvalues and eigenvectors:\n",
      "[4.21431974 0.32486913 1.46081113]\n",
      "[[-0.39711255 -0.88765034 -0.23319198]\n",
      " [-0.52065737  0.42713229 -0.73923874]\n",
      " [-0.75578934  0.17214786  0.63178128]]\n",
      "Solve a simple linear system >> sigma * x = (0, 1, 2)^T:\n",
      "[-2.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "sigma = np.ones((3, 3))\n",
    "sigma[np.diag_indices_from(sigma)] = np.arange(1, 4)\n",
    "print(\"We have the following matrix:\\n\", sigma)\n",
    "print(\"Determinant:\", np.linalg.det(sigma))\n",
    "print(\"Inverse:\\n\", np.linalg.inv(sigma))\n",
    "print(\"Eigenvalues and eigenvectors:\", *np.linalg.eig(sigma), sep='\\n')\n",
    "print(\"Solve a simple linear system >> sigma * x = (0, 1, 2)^T:\", np.linalg.solve(sigma, np.arange(3)), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f2818",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93c627",
   "metadata": {},
   "source": [
    "One particularly helpful package when you work with data that has a table-type structure is `pandas`. Let's import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc1924bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bae5d5",
   "metadata": {},
   "source": [
    "It defines `pandas.DataFrame` class, so we can create dataframes. To create a dataframe, you can call a class constructor `pandas.DataFrame(...)` and pass some data into it. In fact, there are different ways to create dataframes. You can explore them in the corresponding docstring by executing `help(pandas.DataFrame)`.\n",
    "\n",
    "Recall that we had some data in a dictionary format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9891d42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': array([41, 46, 58, 57, 43, 57, 44, 36, 38, 26]),\n",
       " 'female': array([1, 0, 1, 0, 1, 0, 0, 0, 0, 1]),\n",
       " 'occupation': array(['data engineer', 'data engineer', 'tester', 'software engineer',\n",
       "        'data engineer', 'tester', 'data analyst', 'tester',\n",
       "        'software engineer', 'data analyst'], dtype='<U17')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a utility to truncate our dictionary so you can see the structure\n",
    "def truncate_dict(dictionary: dict, start: int, end: int):\n",
    "    truncated_dictionary = {}\n",
    "    for key in dictionary:\n",
    "        truncated_dictionary[key] = dictionary[key][start:end]\n",
    "    return truncated_dictionary\n",
    "\n",
    "truncate_dict(X_dict, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7e8c3",
   "metadata": {},
   "source": [
    "Now let's pass it to the pandas DataFrame constructor to see what it gives us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3787ece5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>tester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>software engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>tester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>data analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>tester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>software engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>data analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  female         occupation\n",
       "0   41       1      data engineer\n",
       "1   46       0      data engineer\n",
       "2   58       1             tester\n",
       "3   57       0  software engineer\n",
       "4   43       1      data engineer\n",
       "5   57       0             tester\n",
       "6   44       0       data analyst\n",
       "7   36       0             tester\n",
       "8   38       0  software engineer\n",
       "9   26       1       data analyst"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(X_dict)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f1650",
   "metadata": {},
   "source": [
    "Dataframes also have useful methods. You can see how we use `.head(...)` method in the above cell. There are also other methods  and properties of dataframes that help us explore their contents, like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ee5f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore the \"tail\":\n",
      "    age  female     occupation\n",
      "95   34       0   data analyst\n",
      "96   45       0  data engineer\n",
      "97   45       0   data analyst\n",
      "98   21       1         tester\n",
      "99   59       0   data analyst\n",
      "Explore what columns the dataframe has: Index(['age', 'female', 'occupation'], dtype='object')\n",
      "Explore the shape and size: (100, 3), 300\n"
     ]
    }
   ],
   "source": [
    "print('Explore the \"tail\":', data.tail(), sep='\\n')\n",
    "print('Explore what columns the dataframe has:', data.columns)  # notice the specific type of the output\n",
    "print('Explore the shape and size:', str(data.shape) + \", \" + str(data.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d2033d",
   "metadata": {},
   "source": [
    "You can access a column of a dataframe using `[]` or call it as a property like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebbfa5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access the \"age\" column:\n",
      "0     41\n",
      "1     46\n",
      "2     58\n",
      "3     57\n",
      "4     43\n",
      "      ..\n",
      "95    34\n",
      "96    45\n",
      "97    45\n",
      "98    21\n",
      "99    59\n",
      "Name: age, Length: 100, dtype: int64\n",
      "\n",
      "Access it as a property of the dataset:\n",
      "0     41\n",
      "1     46\n",
      "2     58\n",
      "3     57\n",
      "4     43\n",
      "      ..\n",
      "95    34\n",
      "96    45\n",
      "97    45\n",
      "98    21\n",
      "99    59\n",
      "Name: age, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Access the \"age\" column:', data[\"age\"], sep='\\n', end='\\n\\n')\n",
    "print('Access it as a property of the dataset:', data.age, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8699f08",
   "metadata": {},
   "source": [
    "But note, that it works only with existing columns. To create a new column, simply provide a name in `[]` right after the name of the dataframe and assign it a specific iterable of a valid size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20b93225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>occupation</th>\n",
       "      <th>wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>21.661334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>24.271417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>tester</td>\n",
       "      <td>30.100009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>software engineer</td>\n",
       "      <td>28.632202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>20.537750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  female         occupation       wage\n",
       "0   41       1      data engineer  21.661334\n",
       "1   46       0      data engineer  24.271417\n",
       "2   58       1             tester  30.100009\n",
       "3   57       0  software engineer  28.632202\n",
       "4   43       1      data engineer  20.537750"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['wage'] = y  # this is the output we have simulated before\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2796601",
   "metadata": {},
   "source": [
    "Note that you can pick specific fields or slices from a dataframe using properties `.loc[...]` and `.iloc[...]`. The former one selects fields based on index names, i.e. names of rows and names of columns (even numeric). The latter one uses indices plainly, like `.loc[1:3, 3]` take elements that lie in the intersection of the 2nd and the 3rd rows with the 4th column, but be careful, that **for** `.loc[...]` both start and end are included if you use slices (unlike usual Python slices) **both start and end are included**, but **for** `.iloc[...]` **start is included and end is excluded**.\n",
    "\n",
    "The following two lines give the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0609f17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>tester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>software engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>tester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>data analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>tester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>software engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>data analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  female         occupation\n",
       "1   46       0      data engineer\n",
       "2   58       1             tester\n",
       "3   57       0  software engineer\n",
       "4   43       1      data engineer\n",
       "5   57       0             tester\n",
       "6   44       0       data analyst\n",
       "7   36       0             tester\n",
       "8   38       0  software engineer\n",
       "9   26       1       data analyst"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1:10, 0:3]\n",
    "data.loc[1:9, [\"age\", \"female\", \"occupation\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9689cc",
   "metadata": {},
   "source": [
    "It is possible (and quite useful) to use boolean iterables for subsetting. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6923e08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For example, we can get all the observations with age between 22 and 40 and wage greater than 20:\n",
      "    age  female         occupation       wage\n",
      "8    38       0  software engineer  20.446357\n",
      "19   40       1  software engineer  20.589102\n",
      "26   37       0  software engineer  20.641106\n",
      "72   38       1      data engineer  20.617162\n",
      "77   38       0       data analyst  20.264496\n",
      "78   39       1  software engineer  21.157447\n",
      "\n",
      "For example, we can get all the observations with age between 22 and 40 and wage greater than 20:\n",
      "    age       wage     occupation\n",
      "0    41  21.661334  data engineer\n",
      "1    46  24.271417  data engineer\n",
      "4    43  20.537750  data engineer\n",
      "6    44  21.613541   data analyst\n",
      "9    26  14.528918   data analyst\n",
      "10   27  14.987409  data engineer\n",
      "11   24  12.530042  data engineer\n",
      "14   42  21.001997   data analyst\n",
      "15   19   8.620657   data analyst\n",
      "23   29  14.897551  data engineer\n",
      "24   19  10.941216   data analyst\n",
      "27   64  32.583040   data analyst\n",
      "28   35  17.749267   data analyst\n",
      "31   38  19.863152   data analyst\n",
      "33   26  13.653395   data analyst\n",
      "34   25  13.522987  data engineer\n",
      "36   27  14.570610   data analyst\n",
      "39   51  26.323680  data engineer\n",
      "42   22  11.717603  data engineer\n",
      "44   38  19.842955   data analyst\n",
      "48   59  30.049282  data engineer\n",
      "50   60  31.842232   data analyst\n",
      "51   22  11.779250  data engineer\n",
      "52   26  13.749733   data analyst\n",
      "55   21   9.824487  data engineer\n",
      "56   42  21.924169   data analyst\n",
      "59   25  10.347298   data analyst\n",
      "61   53  25.994222  data engineer\n",
      "64   46  22.808589  data engineer\n",
      "67   63  31.320346  data engineer\n",
      "69   63  31.443270   data analyst\n",
      "72   38  20.617162  data engineer\n",
      "73   63  30.176033   data analyst\n",
      "75   45  23.084226  data engineer\n",
      "77   38  20.264496   data analyst\n",
      "79   56  26.672464   data analyst\n",
      "80   62  29.764055  data engineer\n",
      "82   34  16.422355   data analyst\n",
      "83   36  19.729330  data engineer\n",
      "84   23  12.000599  data engineer\n",
      "86   43  21.350933  data engineer\n",
      "87   47  23.460450   data analyst\n",
      "88   41  20.997266   data analyst\n",
      "90   24  12.168349   data analyst\n",
      "91   28  14.691256   data analyst\n",
      "92   63  29.472302   data analyst\n",
      "93   28  15.454185   data analyst\n",
      "94   63  31.785895   data analyst\n",
      "95   34  18.181504   data analyst\n",
      "96   45  21.898981  data engineer\n",
      "97   45  23.318810   data analyst\n",
      "99   59  29.020896   data analyst\n"
     ]
    }
   ],
   "source": [
    "print(\"For example, we can get all the observations with age between 22 and 40 and wage greater than 20:\", \n",
    "      data.loc[data.age.between(22, 40) & data.wage.gt(20), :], sep='\\n', end='\\n\\n')\n",
    "\n",
    "print(\"For example, we can get all the observations with age between 22 and 40 and wage greater than 20:\", \n",
    "      data.loc[data.occupation.eq(\"data engineer\") | (data.occupation == \"data analyst\"),  # parentheses are crucial\n",
    "               [\"age\", \"wage\", \"occupation\"]], \n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd375f72",
   "metadata": {},
   "source": [
    "Note the use of element-wise logical operations `&` and `|`. You might also need `~` which is element-wise negation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8dd8d",
   "metadata": {},
   "source": [
    "We can also try to find out what is the type of a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "891b6241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['wage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ae689",
   "metadata": {},
   "source": [
    "That is a pandas series object. These are created to store a sequence of elements, and they provide mathematical and statistical methods to explore this data (so as pandas dataframes have). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f483845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get the maximum wage: 34.90045780193024\n",
      "Get the mean wage: 20.140629344684374\n",
      "Get the min wage: 8.62065713769996\n"
     ]
    }
   ],
   "source": [
    "print(\"Get the maximum wage:\", data['wage'].max())\n",
    "print(\"Get the mean wage:\", data['wage'].mean())\n",
    "print(\"Get the min wage:\", data['wage'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177fb694",
   "metadata": {},
   "source": [
    "Note that you should always try to vectorize mathematical operations with series. The pandas objects allow for that; in fact, proper vectorization is computationally efficient than iterating over objects. As one simple example, let's consider taking a square of age (note: dependence of wage on age is oftenly claimed to be quadratic in labour economics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f9a03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_sq\"] = data.age**2\n",
    "data[\"wage_log\"] = np.log(data.wage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b65720d",
   "metadata": {},
   "source": [
    "You can use `.agg(...)` method to apply different aggregating functions to different columns like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdd41fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age     39.160000\n",
       "wage    34.900458\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.agg({\"age\": np.mean, \"wage\": max})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae7ee5d",
   "metadata": {},
   "source": [
    "This is a powerful tool which you will most likely use later too.\n",
    "\n",
    "Several technical, but useful methods would be `.replace(...)`, `.drop(...)`, and `.rename(...)`.\n",
    "\n",
    "Let's suppose that we want to replace some values to NaNs (just as example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "017d1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['occupation'] = data.occupation.replace([\"tester\", \"software engineer\"], np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ede30c5",
   "metadata": {},
   "source": [
    "And now we can drop all the rows that contain NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8da2bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74768eb1",
   "metadata": {},
   "source": [
    "You can try to get an index of the new dataframe using `.method` propery of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3546df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c256a2fe",
   "metadata": {},
   "source": [
    "You can see, that after we dropped some rows, indices did not change. Now, if we would try to slice the dataframe with `.loc[]` property, then we could encounter problems (whereas `.iloc[]` would work). To avoid problems, it is recommended to reset the indices after untroducing changes to the original dataset (if you do not need old indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "811e9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e186d5d",
   "metadata": {},
   "source": [
    "You can drop columns (or rows) using the following method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45505459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['wage'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6099e",
   "metadata": {},
   "source": [
    "We can also rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d7a022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'age': 'experience', 'age_sq': 'experience_sq'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36633455",
   "metadata": {},
   "source": [
    "Note that you could also rename your row indices.\n",
    "\n",
    "It is very important to pay attention to the `inplace` parameters in pandas methods you use, because it defines whether a method mutates an initial object or returns a new one.\n",
    "\n",
    "In addition, whenever you want to create a new dataframe from an existing one, consider using `.copy()` method that returns a copy of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bb38c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data.loc[0:100, [\"wage_log\", \"experience\", \"occupation\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406db251",
   "metadata": {},
   "source": [
    "The problem is in how Python handles assignments. In this case a new variable would refer to an old one, and changes to the new one can mutate the original object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6ec8a",
   "metadata": {},
   "source": [
    "You can simply save your data to a file using `.to_...` methods, like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('class_5_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ea42c",
   "metadata": {},
   "source": [
    "To read this data later, use functions of form `pandas.read_...`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e811e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_read = pd.read_csv('class_5_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6aa48a",
   "metadata": {},
   "source": [
    "## Afterword\n",
    "\n",
    "Of course, pandas and numpy are massive packages. The information in this notebook provides you with basic objects, their properties and methods in Pandas, so you can get acquainted with it build up on that knowledge further.\n",
    "\n",
    "Some of the topics that we have not covered here but can be of your interest in Pandas (so feel free to check them up):\n",
    "\n",
    "* multi-indexing\n",
    "* plotting with pandas (and in general with `matplotlib`)\n",
    "* mapping functions to series (but alwas try to vectorize computations, then you won't need it often), one of the use cases is \"renaming\" values (use dictionary).\n",
    "* datetime format\n",
    "\n",
    "For sure, you should not stop on that. Your journey just begins. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
